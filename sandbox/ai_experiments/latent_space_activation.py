from langchain_ollama import ChatOllama
from langchain_core.messages import HumanMessage, BaseMessage

class ReasoningAgent:
    """
    A class that uses a large language model to perform various reasoning tasks.
    It can generate expert responses, ask follow-up questions, grade responses,
    and reformat text. The agent's behavior can be influenced by a "latent space control" string.
    """

    def __init__(
        self,
        model: str = "qwen2:0.5b",
        temperature: float = 0.4,
        num_predict: int = -1,
        latent_space_control: str = "",
    ):
        """
        Initializes the ReasoningAgent.

        Args:
            model: The name of the Ollama model to use (e.g., "qwen2:0.5b").
                   Ensure the model is available locally.
            temperature: The temperature for the model's sampling.
            num_predict: The number of tokens to predict. -1 for unlimited.
            latent_space_control: A string to influence the generation process.
        """
        self.bot = ChatOllama(model=model, temperature=temperature, num_predict=num_predict)
        self.latent_space_control = latent_space_control

    def set_latent_space_control(self, control_string: str):
        """Sets the latent space control string to influence future generations."""
        self.latent_space_control = control_string

    def _invoke_model(self, prompt: str) -> BaseMessage:
        """
        Private method to invoke the language model with a given prompt.

        Args:
            prompt: The complete prompt to send to the model.

        Returns:
            A BaseMessage object containing the model's response.
        """
        final_prompt = prompt
        if self.latent_space_control:
            final_prompt += f"\n\nConsider this guiding principle: {self.latent_space_control}"

        messages = [HumanMessage(content=final_prompt)]
        return self.bot.invoke(messages)

    def expert_bot(self, user_input: str) -> BaseMessage:
        """
        Generates an expert-level output based on the user's input, influenced
        by the latent space control string.

        Args:
            user_input: The initial input/question from the user.

        Returns:
            A BaseMessage containing the expert's response.
        """
        prompt = f"Generate an expert-level response for the following: {user_input}"
        return self._invoke_model(prompt)

    def interigator_bot(self, user_input: str, expert_output: BaseMessage) -> BaseMessage:
        """
        Asks a follow-up question based on the user's input and the expert's output.

        Args:
            user_input: The initial input/question from the user.
            expert_output: The response generated by the expert_bot.

        Returns:
            A BaseMessage containing the follow-up question.
        """
        prompt = f'''Initial user input: {user_input}
Expert's response: {expert_output.content}
Based on this, ask a concise follow-up question to the expert.'''
        return self._invoke_model(prompt)

    def grading_bot(self, user_input: str, expert_output: BaseMessage) -> BaseMessage:
        """
        Grades the expert's response out of 5 and suggests improvements.

        Args:
            user_input: The initial input/question from the user.
            expert_output: The response generated by the expert_bot.

        Returns:
            A BaseMessage containing the grading and improvement suggestions.
        """
        prompt = f'''Initial user input: {user_input}
Expert's response: {expert_output.content}
Grade the expert's response out of 5 and suggest improvements.'''
        return self._invoke_model(prompt)

    def reformatter_bot(self, expert_output: BaseMessage) -> BaseMessage:
        """
        Refactors the expert's output into a comprehensive textbook section.

        Args:
            expert_output: The response generated by the expert_bot.

        Returns:
            A BaseMessage containing the reformatted textbook section.
        """
        prompt = f"Reformat the following expert response into a comprehensive textbook section, expanding on the topic with domain-expert knowledge: {expert_output.content}"
        return self._invoke_model(prompt)
